{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DwZp0rPuuSo"
      },
      "outputs": [],
      "source": [
        "# Assignment: Exploring Transformers with Pretrained Text Generation Models\n",
        "# By: Harsh Chavva"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "y6r3d4PYwhOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GPT-2 text generation model\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Set your prompt\n",
        "prompt = 'In the future, education will'\n",
        "\n",
        "# Generate text\n",
        "result = generator(prompt, max_length = 50, temperature = 0.7)\n",
        "print(result[0]['generated_text'])\n",
        "\n",
        "# Experiment with different prompts\n",
        "prompt = 'The impact of AI on the future of work'\n",
        "result = generator(prompt, max_length = 50, temperature = 0.8)\n",
        "print(\"\\nAI Impact on Future Work Output:\\n\", result[0]['generated_text'])\n",
        "\n",
        "prompt = 'Once upon a time, there was a kingdom'\n",
        "result = generator(prompt, max_length = 100, temperature = 0.6)\n",
        "print(\"\\ Once upon a time Story Output:\\n\", result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5zcvMTIu8Jd",
        "outputId": "bc44e2ff-b12d-4c54-96b8-9fe0be35e811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the future, education will become a political issue.\n",
            "\n",
            "\"Yes, you can't have free speech anywhere,\" she said. \"But you can have free speech in public. If you want to fight for your rights, you've got to go through the process that we've already done.\"\n",
            "\n",
            "The law passed in November, with support from the governor's office, is expected to be signed into law by Gov. Charlie Baker in January.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AI Impact on Future Work Output:\n",
            " The impact of AI on the future of work has always been a matter of concern, for it has always been to the detriment of those with the most significant work experience. But the time has come for us to reconsider this issue. The work of AI with the ability to predict what employers and employers will do with your employee's work at any given time, as well as in an effort to provide the benefit, will be extremely important for the future of our society as well.\n",
            "\n",
            "To begin with, we are working with AI to develop new algorithms that can predict what jobs are likely to be taken of employees with little or no experience in AI. Many of these new algorithms will be based on real-time data collected over a period of time from a variety of sources.\n",
            "\n",
            "We are also working with the AI to develop an interactive, automated, and personalized workforce management program based on the principles of Artificial Intelligence, which is at the core of AI, which will be a critical component of our long term plans. In a nutshell, we are working with the AI to develop an integrated workforce management programme that will include the following:\n",
            "\n",
            "a human resource manager who can guide the AI's decisions and have guidance to help ensure the team is prepared to support the AI in its tasks\n",
            "\n",
            "a human resource coordinator who will\n",
            "\\ Once upon a time Story Output:\n",
            " Once upon a time, there was a kingdom, but it was not strong enough. The king of the kingdom came out and said to me, \"You will come to the king of the kingdom at once.\" And I said, \"Yes, I will come to the king of the kingdom at once.\" And he said, \"I will come to you before the king of the kingdom comes out. And you shall not go out to the king of the kingdom. But you shall come out to the king of the kingdom before the king of the kingdom comes out.\" And I said, \"Yes, I shall come to you before the king of the kingdom comes out.\" And he said, \"I will come to you before the king of the kingdom comes out.\" And I said, \"Yes, I shall come to you before the king of the kingdom comes out.\" And he said, \"You shall not go out to the king of the kingdom after the king of the kingdom comes out.\" And I said, \"Yes, I shall come to you after the king of the kingdom comes out.\" And he said, \"You shall not go out to the king of the kingdom after the king of the kingdom comes out.\" And I said, \"Yes, I shall come to you after the king of the kingdom comes out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GPT-2 text generation model\n",
        "generator = pipeline(\"text-generation\", model = \"gpt2\")\n",
        "\n",
        "# --- Prompt 1: News Headline ---\n",
        "prompt = \"Breaking news: Scientists discover\"\n",
        "result = generator(prompt, max_length = 60, temperature = 0.7)\n",
        "print(\"\\nNews Headline Output:\\n\", result[0]['generated_text'])\n",
        "\n",
        "# --- Prompt 2: Short Story Opener ---\n",
        "prompt = \"Once upon a time in a hidden forest,\"\n",
        "result = generator(prompt, max_length = 100, temperature = 0.6)\n",
        "print(\"\\nShort Story Output:\\n\", result[0]['generated_text'])\n",
        "\n",
        "# --- Prompt 3: Dialogue ---\n",
        "prompt = \"Person A: How did you find this place?\\nPerson B:\"\n",
        "result = generator(prompt, max_length = 80, temperature = 0.9)\n",
        "print(\"\\nDialogue Output:\\n\", result[0]['generated_text'])\n",
        "\n",
        "# --- Prompt 4: Factual Question ---\n",
        "prompt = \"What is the capital of Australia?\"\n",
        "result = generator(prompt, max_length = 50, temperature = 0.5)\n",
        "print(\"\\nFactual Statement Output:\\n\", result[0]['generated_text'])\n",
        "\n",
        "# --- Prompt 5: Generate Multiple Variations ---\n",
        "prompt = \"The future of space exploration involves\"\n",
        "results = generator(prompt, max_length = 60, temperature = 0.8, num_return_sequences = 3)\n",
        "print(\"\\nMultiple Variations on the Same Prompt:\")\n",
        "for i, res in enumerate(results, 1):\n",
        "    print(f\"\\nVariation {i}:\\n{res['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qIN8NgSyxub",
        "outputId": "c0aecd56-4f2c-4982-952c-0e36df866459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "News Headline Output:\n",
            " Breaking news: Scientists discover new species of jellyfish in the ocean\n",
            "\n",
            "Scientists have known for a while that jellyfish are a good bet to form their own artificial reef. But now a team from the University of California, Los Angeles (UCLA) has found that they could be so much more useful than the jellyfish that they're actually a threat.\n",
            "\n",
            "The team found that the new species of jellyfish - named Pterosauridae - that they discovered in the waters of the Pacific have a unique niche where they can form their own artificial reefs.\n",
            "\n",
            "\"We think that the jellyfish are a real threat to the reef because they can form their own artificial reefs,\" said lead researcher John Wiens, a postdoctoral researcher at UCLA's Department of Biological Sciences. \"What they do is create artificial reefs by producing a substance called lipid that is found in the water. They are thought to be essential for the production of oxygen in the water-base, which is what they need in order to survive off the reef.\"\n",
            "\n",
            "This new species of jellyfish is found in the Pacific Ocean, and scientists believe that they can provide the jellyfish with the necessary oxygen that helps them survive off the reef. Credit: UCLA and UCLA\n",
            "\n",
            "The new species of jellyfish has\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Short Story Output:\n",
            " Once upon a time in a hidden forest, the two men were standing on the edge of a huge rock.\n",
            "\n",
            "\"I'm sorry, I didn't know you had a brother, but I'm afraid he's gone too far,\" said the man, who didn't want to be identified.\n",
            "\n",
            "\"What are you guys doing here?\" asked the man, who was wearing a black suit and a white shirt with a black belt.\n",
            "\n",
            "\"What are you guys doing here?\" asked the man, who didn't want to be identified.\n",
            "\n",
            "\"I'm not a man,\" the man said. \"I was only looking for a friend. I'm not a man, I'm a man.\"\n",
            "\n",
            "The man looked at the other man, who had a black belt and black belt in black.\n",
            "\n",
            "\"What do you think you're doing here?\" asked the man, who was wearing a black belt and black belt in black.\n",
            "\n",
            "\"I'm not a man,\" said the man, who was wearing a black belt and black belt in black.\n",
            "\n",
            "The man, who was wearing a black belt and black belt in black, suddenly looked away.\n",
            "\n",
            "\"But I'm not a man,\" the man said.\n",
            "\n",
            "\"I'm a man,\" said the man,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dialogue Output:\n",
            " Person A: How did you find this place?\n",
            "Person B: I've never been to this place.\n",
            "Person A: How did you find this place?\n",
            "Person B: I have a dream. I woke up in the middle of the night feeling a strange, weird, creepy feeling. And then I thought some strange thing, something that I thought was an animal, I thought was a creature, and suddenly went to sleep. I woke up in the middle of the night with strange, strange feelings.\n",
            "Person A: But what are you doing here?\n",
            "Person B: I thought I'm in the wilderness. So, what's going on?\n",
            "Person A: Why are you here?\n",
            "Person B: Like I said, I remember feeling strange. I don't remember feeling strange.\n",
            "Person A: What would you like to do then?\n",
            "Person B: I don't remember who I am now. I don't remember being a human anymore. I don't remember anything that is going on, I don't remember even getting back in time. I don't remember anything else. Now, this dream will be mine forever.\n",
            "Person A: Then what are you going to do?\n",
            "Person B: I don't remember something right now. The whole time I was dreaming. But now, it's me.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Factual Statement Output:\n",
            " What is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland. The capital of Australia is the state of New South Wales. The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of New South Wales. The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of New South Wales. The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "The capital of Australia is the state of Queensland.\n",
            "\n",
            "Where is the capital of Australia?\n",
            "\n",
            "Multiple Variations on the Same Prompt:\n",
            "\n",
            "Variation 1:\n",
            "The future of space exploration involves a new, better, faster and more powerful rocket. It's now being developed by Lockheed Martin, and it is expected to be ready in just a few weeks.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "\"The space shuttle has been a great success and we believe we have a strong chance of getting to the moon in about 20-25 years,\" said Lockheed Martin Chief Executive Officer Martin Schulman in a recent interview with CNBC. \"We're really excited about the new technology and we're excited to use it. That's what the big question is about.\"\n",
            "\n",
            "Schulman says that as the first space shuttle completes a test flight in 2022, he says those who take it are not just looking for a new test vehicle to test out their technology, they are looking for a reusable vehicle.\n",
            "\n",
            "\"All of the pieces are in place, and we're going to be able to take it to the moon,\" Schulman said of the shuttle.\n",
            "\n",
            "Space and space travel are rapidly changing and, as the last generation of rockets took off from the moon in 1973, there are still a lot of gaps in technology. The space shuttle has already completed its first tests, and it has already proved that the rocket can fly to the International Space Station.\n",
            "\n",
            "Advertisement\n",
            "\n",
            "\n",
            "Variation 2:\n",
            "The future of space exploration involves exploring the world's most remote regions with a combination of sensors, cameras, and other technologies. NASA has been developing this capability for the past three decades. The agency is now planning to develop an orbital satellite system to carry astronauts to the moon, Mars, and other destinations.\n",
            "\n",
            "The U.S. Space Shuttle program is the world's largest space launch fleet. The shuttle program, which began in 1997, is powered by a combination of Boeing Co.'s Pratt & Whitney Research Center (PLR) and Lockheed Martin Corp.'s Space Systems Command.\n",
            "\n",
            "NASA launched the Space Shuttle program in 1978, and is now developing a robotic orbital mission system, called the Commercial Crew Program. Space shuttle missions have been piloted on the International Space Station for nearly 30 years.\n",
            "\n",
            "The launch of the Space Shuttle Program has the potential to provide a new frontier for the government and industry of space exploration and human-on-Earth relations. NASA is working with private companies to build and operate one or more commercial missions to the Moon or beyond in the coming decades.\n",
            "\n",
            "The first mission to the Moon will be launched in 2020, followed by a third mission in 2035. In 2016, NASA will launch 20 missions to the Moon and bring them to Earth.\n",
            "\n",
            "\n",
            "\n",
            "Variation 3:\n",
            "The future of space exploration involves a lot of work. And that's where the Falcon 9 story comes in.\n",
            "\n",
            "It's been a long time coming, but SpaceX chief executive Elon Musk says that's about to change.\n",
            "\n",
            "\"We are in the midst of a fantastic project,\" Musk said in an interview with Business Insider. \"The rockets are really going to be making this country great again, and that's the mission that we are going to get out of there. And we're going to have a lot more human spaceflight than what we've been doing for the last 10, 20 years.\"\n",
            "\n",
            "The Falcon 9 mission, which will be used to ferry a cargo of astronauts to the International Space Station, is one of SpaceX's major milestones after a recent rocket launch. But Musk hasn't made it official for a full flight yet.\n",
            "\n",
            "The company had earlier said that SpaceX would launch its first commercial manned spaceflight vehicle in 2014. That launch would be the first since the launch of the Falcon 9 in 2005.\n",
            "\n",
            "SpaceX is still building the Falcon 9, but it's getting ready to go under the hood and take a step closer to commercial launch.\n",
            "\n",
            "In July, SpaceX announced the launch of its second rocket -- the Merlin 1D engine -- into space.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Takeaways\n",
        "### 1. Patterns Noticed in the Generated Text\n",
        "- GPT-2 often continues text in a grammatically correct but open-ended way\n",
        "- It favors speculative and narrative styles, especially with creative prompts like “Once upon a time…” or “In the future…”\n",
        "- The model tends to avoid finality, most outputs feel like mid-thought or the beginning of a longer continuation\n",
        "- It starts using repetitive or filler phrases when close to the token limit (max_length)\n",
        "\n",
        "### 2. Effect of Changing Temperature on Creativity and Coherence\n",
        "- Lower temperatures (0.5–0.6):\n",
        "  - More predictable and factually stable\n",
        "  - Generated text is coherent and easy to understand but sometimes dull\n",
        "- Mid-range temperature (0.7):\n",
        "  - Balanced creativity and coherence; useful for headlines or semi-formal text\n",
        "- Higher temperatures (0.8–0.9):\n",
        "  - More imaginative and diverse outputs\n",
        "  - Can become less logically coherent or stray off-topic in longer outputs\n",
        "\n",
        "### 3. Prompts That Yielded the Most Coherent Results\n",
        "- Informational and structured prompts, such as:\n",
        "  - “The impact of AI on the future of work”\n",
        "  - “What is the capital of Australia?” (though GPT-2 may hallucinate factual answers)\n",
        "- Narrative openers (e.g., “Once upon a time in a hidden forest,”) also produce smooth, stylistically appropriate outputs\n",
        "- Dialogue prompts showed character-driven, coherent interaction—though less reliable in maintaining context\n",
        "\n",
        "### 4. Observed Limitations of GPT-2\n",
        "- Factual inaccuracy: GPT-2 is not connected to real-time data and may generate plausible but incorrect information\n",
        "- Context retention: It has a short memory window—longer logical chains or continuity across paragraphs often fail\n",
        "- Bias and randomness: High temperatures can introduce bizarre or inappropriate outputs\n",
        "- Lack of world knowledge after 2019: Cannot reflect events, facts, or cultural updates beyond its training cutoff"
      ],
      "metadata": {
        "id": "WSoYgnWp_3gM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXAHQ-FsAPuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}